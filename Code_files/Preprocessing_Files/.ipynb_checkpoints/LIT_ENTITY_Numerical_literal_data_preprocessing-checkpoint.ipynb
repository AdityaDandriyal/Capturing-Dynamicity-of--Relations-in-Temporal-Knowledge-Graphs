{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ejm-HtawpmkQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y5O-4HOypndp",
    "outputId": "829b25c5-ddbd-4587-c973-261efe12e777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charlie_Hartfield\twasBornOnDate\t1971\n",
      "Sven_Ratke\twasBornOnDate\t1972\n",
      "Jens_Petersen\twasBornOnDate\t1941\n",
      "Brian_Linighan\twasBornOnDate\t1973\n",
      "Rick_Scott\twasBornOnDate\t1952\n",
      "Tomi_Petrescu\twasBornOnDate\t1986\n",
      "Avery_Brundage\tdiedOnDate\t1975\n",
      "Werner_Herzog\twasBornOnDate\t1942\n",
      "Ngaio_Marsh\twasCreatedOnDate\t2010\n",
      "Berry_Gordy\twasBornOnDate\t1929\n",
      "Anderson_Conceição_Xavier\twasBornOnDate\t1980\n",
      "Caldwell,_New_Jersey\twasCreatedOnDate\t1892\n",
      "Andreas_Avraam\twasBornOnDate\t1987\n",
      "Tia_Carrere\twasBornOnDate\t1967\n",
      "Giants_vs._Yanks\twasCreatedOnDate\t1923\n"
     ]
    }
   ],
   "source": [
    "# Specify the file path\n",
    "file_path = '/content/drive/MyDrive/numerical_literals.txt'\n",
    "\n",
    "# Specify the number of lines to read\n",
    "num_lines_to_read = 15\n",
    "\n",
    "# Open the file in read mode ('r')\n",
    "with open(file_path, 'r') as file:\n",
    "    # Read the specified number of lines\n",
    "    for _ in range(num_lines_to_read):\n",
    "        line = file.readline()\n",
    "\n",
    "        # Check if the line is not empty (end of file)\n",
    "        if not line:\n",
    "            break\n",
    "\n",
    "        # Process or print the line\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sIC_CzK3pngX"
   },
   "outputs": [],
   "source": [
    "def copy_lines_with_repeated_values(input_file_path, output_file_path):\n",
    "    # Dictionary to store counts of first column values\n",
    "    counts = {}\n",
    "\n",
    "    # Read the content of the input file\n",
    "    with open(input_file_path, 'r') as input_file:\n",
    "        lines = input_file.readlines()\n",
    "\n",
    "    # Iterate through lines to count occurrences\n",
    "    for line in lines:\n",
    "        value = line.split('\\t')[0]  # Assuming columns are tab-separated\n",
    "        counts[value] = counts.get(value, 0) + 1\n",
    "\n",
    "    # Write lines with repeated values to the output file\n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        for line in lines:\n",
    "            value = line.split('\\t')[0]  # Assuming columns are tab-separated\n",
    "            if counts[value] > 1:\n",
    "                output_file.write(line)\n",
    "\n",
    "# Define file paths\n",
    "input_file_path = '/content/drive/MyDrive/numerical_literals.txt'\n",
    "output_file_path = '/content/drive/MyDrive/filtered_literal_data.txt'\n",
    "\n",
    "# Copy lines with repeated values to the output file\n",
    "copy_lines_with_repeated_values(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JfwtGkcDxwUT"
   },
   "outputs": [],
   "source": [
    "def fix_date_format(input_file_path, output_file_path):\n",
    "    # Read the content of the input file\n",
    "    with open(input_file_path, 'r') as input_file:\n",
    "        lines = input_file.readlines()\n",
    "\n",
    "    # Fix date format in the third column\n",
    "    fixed_lines = [fix_date(line) for line in lines]\n",
    "\n",
    "    # Write the fixed lines to the output file\n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        output_file.writelines(fixed_lines)\n",
    "\n",
    "def fix_date(line):\n",
    "    # Split the line into columns\n",
    "    columns = line.split()\n",
    "\n",
    "    # Check if the date in the third column has a length of 3\n",
    "    if len(columns) >= 3 and len(columns[2]) == 3:\n",
    "        # Add a zero before the date to make its length 4\n",
    "        columns[2] = '0' + columns[2]\n",
    "\n",
    "    # Join the columns back into a line\n",
    "    return '\\t'.join(columns) + '\\n'\n",
    "\n",
    "# Define file paths\n",
    "input_file_path = '/content/drive/MyDrive/filtered_literal_data.txt'\n",
    "output_file_path = '/content/drive/MyDrive/filtered_literal_data.txt'\n",
    "\n",
    "# Fix date format in the third column\n",
    "fix_date_format(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hcaqASwiuxcJ"
   },
   "outputs": [],
   "source": [
    "# Input file path\n",
    "input_file_path = '/content/drive/MyDrive/filtered_literal_data.txt'\n",
    "\n",
    "# Output file path\n",
    "output_file_path = '/content/drive/MyDrive/num_lit_entity2id.txt'\n",
    "\n",
    "# Dictionary to store unique values and corresponding integers\n",
    "unique_values_dict = {}\n",
    "\n",
    "# Read the input file and extract unique values\n",
    "with open(input_file_path, 'r') as input_file:\n",
    "    for line in input_file:\n",
    "        # Split the line into elements\n",
    "        elements = line.strip().split()\n",
    "\n",
    "        # Check if there's at least one element\n",
    "        if elements:\n",
    "            # Extract the first element\n",
    "            first_element = elements[0]\n",
    "\n",
    "            # If the value is not in the dictionary, add it with a unique integer\n",
    "            if first_element not in unique_values_dict:\n",
    "                unique_values_dict[first_element] = len(unique_values_dict)\n",
    "\n",
    "# Read the input file and extract unique values\n",
    "with open(input_file_path, 'r') as input_file:\n",
    "    for line in input_file:\n",
    "        # Split the line into elements\n",
    "        elements = line.strip().split()\n",
    "\n",
    "        # Check if there's at least one element\n",
    "        if elements:\n",
    "            # Extract the first element\n",
    "            third_element = elements[2]\n",
    "\n",
    "            # If the value is not in the dictionary, add it with a unique integer\n",
    "            if third_element not in unique_values_dict:\n",
    "                unique_values_dict[third_element] = len(unique_values_dict)\n",
    "\n",
    "# Write unique values with <> symbols and unique integers to the output file\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    for value, unique_integer in unique_values_dict.items():\n",
    "        output_file.write(f'<{value}>  \\t{unique_integer}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pF3iZlvQpnjG"
   },
   "outputs": [],
   "source": [
    "# Input file path\n",
    "input_file_path = '/content/drive/MyDrive/filtered_literal_data.txt'\n",
    "\n",
    "# Output file path\n",
    "output_file_path = '/content/drive/MyDrive/USEnum_lit_entity2id.txt'\n",
    "\n",
    "# Dictionary to store unique values and corresponding integers\n",
    "unique_values_dict = {}\n",
    "\n",
    "# Read the input file and extract unique values\n",
    "with open(input_file_path, 'r') as input_file:\n",
    "    for line in input_file:\n",
    "        # Split the line into elements\n",
    "        elements = line.strip().split()\n",
    "\n",
    "        # Check if there's at least one element\n",
    "        if elements:\n",
    "            # Extract the first element\n",
    "            first_element = elements[0]\n",
    "\n",
    "            # If the value is not in the dictionary, add it with a unique integer\n",
    "            if first_element not in unique_values_dict:\n",
    "                unique_values_dict[first_element] = len(unique_values_dict)\n",
    "\n",
    "# Read the input file and extract unique values\n",
    "with open(input_file_path, 'r') as input_file:\n",
    "    for line in input_file:\n",
    "        # Split the line into elements\n",
    "        elements = line.strip().split()\n",
    "\n",
    "        # Check if there's at least one element\n",
    "        if elements:\n",
    "            # Extract the first element\n",
    "            third_element = elements[2]\n",
    "\n",
    "            # If the value is not in the dictionary, add it with a unique integer\n",
    "            if third_element not in unique_values_dict:\n",
    "                unique_values_dict[third_element] = len(unique_values_dict)\n",
    "\n",
    "# Write unique values with <> symbols and unique integers to the output file\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    for value, unique_integer in unique_values_dict.items():\n",
    "        output_file.write(f'{value}  \\t{unique_integer}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CAmc5s_Cpnln"
   },
   "outputs": [],
   "source": [
    "# Input file path\n",
    "input_file_path = '/content/drive/MyDrive/filtered_literal_data.txt'\n",
    "\n",
    "# Output file path\n",
    "output_file_path = '/content/drive/MyDrive/num_lit_relation2id.txt'\n",
    "\n",
    "# Dictionary to store unique values and corresponding integers\n",
    "unique_values_dict = {}\n",
    "\n",
    "# Read the input file and extract unique values\n",
    "with open(input_file_path, 'r') as input_file:\n",
    "    for line in input_file:\n",
    "        # Split the line into elements\n",
    "        elements = line.strip().split()\n",
    "\n",
    "        # Check if there's at least one element\n",
    "        if elements:\n",
    "            # Extract the first element\n",
    "            second_element = elements[1]\n",
    "\n",
    "            # If the value is not in the dictionary, add it with a unique integer\n",
    "            if second_element not in unique_values_dict:\n",
    "                unique_values_dict[second_element] = len(unique_values_dict)\n",
    "\n",
    "# Write unique values with <> symbols and unique integers to the output file\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    for value, unique_integer in unique_values_dict.items():\n",
    "        output_file.write(f'<{value}>  \\t{unique_integer}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LfuUxaO8vSdm"
   },
   "outputs": [],
   "source": [
    "# Input file path\n",
    "input_file_path = '/content/drive/MyDrive/filtered_literal_data.txt'\n",
    "\n",
    "# Output file path\n",
    "output_file_path = '/content/drive/MyDrive/USEnum_lit_relation2id.txt'\n",
    "\n",
    "# Dictionary to store unique values and corresponding integers\n",
    "unique_values_dict = {}\n",
    "\n",
    "# Read the input file and extract unique values\n",
    "with open(input_file_path, 'r') as input_file:\n",
    "    for line in input_file:\n",
    "        # Split the line into elements\n",
    "        elements = line.strip().split()\n",
    "\n",
    "        # Check if there's at least one element\n",
    "        if elements:\n",
    "            # Extract the first element\n",
    "            second_element = elements[1]\n",
    "\n",
    "            # If the value is not in the dictionary, add it with a unique integer\n",
    "            if second_element not in unique_values_dict:\n",
    "                unique_values_dict[second_element] = len(unique_values_dict)\n",
    "\n",
    "# Write unique values with <> symbols and unique integers to the output file\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    for value, unique_integer in unique_values_dict.items():\n",
    "        output_file.write(f'{value}  \\t{unique_integer}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9CC3riO3kiMc"
   },
   "outputs": [],
   "source": [
    "entity2id_path = '/content/drive/MyDrive/USEnum_lit_entity2id.txt'\n",
    "relation2id_path = '/content/drive/MyDrive/USEnum_lit_relation2id.txt'\n",
    "\n",
    "# Read entity2id and relation2id mappings\n",
    "entity_mapping = {}\n",
    "relation_mapping = {}\n",
    "\n",
    "with open(entity2id_path, 'r') as entity_file:\n",
    "    for line in entity_file:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) == 2:\n",
    "            entity_mapping[parts[0].strip()] = parts[1]\n",
    "\n",
    "with open(relation2id_path, 'r') as relation_file:\n",
    "    for line in relation_file:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) == 2:\n",
    "            relation_mapping[parts[0].strip()] = parts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wvbIxUI5pntp"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def map_values_to_integers(input_file_path, output_file_path, entity_mapping, relation_mapping):\n",
    "    # Read the content of the input file\n",
    "    with open(input_file_path, 'r') as input_file:\n",
    "        lines = input_file.readlines()\n",
    "\n",
    "    # Replace text values with corresponding integers\n",
    "    for i in range(len(lines)):\n",
    "        elements = lines[i].strip().split('\\t')\n",
    "        if elements:\n",
    "            # Replace entity values\n",
    "            if elements[0] in entity_mapping:\n",
    "                lines[i] = lines[i].replace(elements[0], str(entity_mapping[elements[0]]))\n",
    "\n",
    "            if elements[2] in entity_mapping:\n",
    "                lines[i] = lines[i].replace(elements[2], str(entity_mapping[elements[2]]))\n",
    "\n",
    "\n",
    "            # Replace relation values\n",
    "            if elements[1] in relation_mapping:\n",
    "                lines[i] = lines[i].replace(elements[1], str(relation_mapping[elements[1]]))\n",
    "\n",
    "\n",
    "\n",
    "    # Write the modified content to the output file\n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        output_file.writelines(lines)\n",
    "\n",
    "# Define file paths\n",
    "input_file_path = '/content/drive/MyDrive/filtered_literal_data.txt'\n",
    "output_file_path = '/content/drive/MyDrive/num_lit_triple2id.txt'\n",
    "\n",
    "\n",
    "# Apply mappings to the input file and write to the output file\n",
    "map_values_to_integers(input_file_path, output_file_path, entity_mapping, relation_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Z1gHlLQnbhr"
   },
   "outputs": [],
   "source": [
    "inverse_entity_mapping = {v: k for k, v in entity_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bHmk2jF3ytF2"
   },
   "outputs": [],
   "source": [
    "def duplicate_last_column_for_repeated_values(input_file_path, output_file_path):\n",
    "    # Dictionary to store counts of first column values\n",
    "    counts = {}\n",
    "\n",
    "    # Read the content of the input file\n",
    "    with open(input_file_path, 'r') as input_file:\n",
    "        lines = input_file.readlines()\n",
    "\n",
    "\n",
    "    # Write lines with repeated values and duplicated last column to the output file\n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        for line in lines:\n",
    "          dup_ele = (line.split().copy())[-1]\n",
    "          output_file.write(line.strip() + '\\t' + inverse_entity_mapping[str(dup_ele)] + '\\t' + inverse_entity_mapping[str(dup_ele)] + '\\n')\n",
    "\n",
    "# Define file paths\n",
    "input_file_path = '/content/drive/MyDrive/num_lit_triple2id.txt'\n",
    "output_file_path = '/content/drive/MyDrive/TEMPORAL_num_lit_triple2id.txt'\n",
    "\n",
    "# Duplicate last column for lines with repeated values to the output file\n",
    "duplicate_last_column_for_repeated_values(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fCd-SMBrpuao"
   },
   "outputs": [],
   "source": [
    "def duplicate_last_column_for_repeated_values(input_file_path, output_file_path):\n",
    "    # Dictionary to store counts of first column values\n",
    "    counts = {}\n",
    "\n",
    "    # Read the content of the input file\n",
    "    with open(input_file_path, 'r') as input_file:\n",
    "        lines = input_file.readlines()\n",
    "\n",
    "\n",
    "    # Write lines with repeated values and duplicated last column to the output file\n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        for line in lines:\n",
    "          dup_ele = (line.split().copy())[-1]\n",
    "          output_file.write(line.strip() + '\\t' + inverse_entity_mapping.get(dup_ele) + '\\t' + inverse_entity_mapping.get(dup_ele) + '\\n')\n",
    "\n",
    "# Define file paths\n",
    "input_file_path = '/content/drive/MyDrive/num_lit_triple2id.txt'\n",
    "output_file_path = '/content/drive/MyDrive/(copy)TEMPORAL_num_lit_triple2id.txt'\n",
    "\n",
    "# Duplicate last column for lines with repeated values to the output file\n",
    "duplicate_last_column_for_repeated_values(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H-HJ4vW1pn2M"
   },
   "outputs": [],
   "source": [
    "def create_training_set_and_remove(input_file_path, train_file_path):\n",
    "    # Read the content of the input file\n",
    "    with open(input_file_path, 'r') as input_file:\n",
    "        lines = input_file.readlines()\n",
    "\n",
    "    # Extract unique values from the first column and the third column:\n",
    "    unique_values = set()\n",
    "    for line in lines:\n",
    "        elements = line.strip().split('\\t')\n",
    "        if len(elements) >= 4:\n",
    "            unique_values.add(elements[0])\n",
    "            unique_values.add(elements[2])\n",
    "\n",
    "    # Initialize the training set and set to track included values\n",
    "    training_set = []\n",
    "    included_values = set()\n",
    "\n",
    "    # Iterate through lines to create the training set\n",
    "    for line in lines:\n",
    "        value1 = line.split()[0]\n",
    "        value2 = line.split()[2]\n",
    "\n",
    "        # Include the line in the training set if it has a unique value\n",
    "        if value1 in unique_values and value1 not in included_values:\n",
    "            training_set.append(line)\n",
    "            included_values.add(value1)\n",
    "            included_values.add(value2)\n",
    "\n",
    "        if value2 in unique_values and value2 not in included_values:\n",
    "            training_set.append(line)\n",
    "            included_values.add(value1)\n",
    "            included_values.add(value2)\n",
    "\n",
    "\n",
    "    # Write the training set to the training file\n",
    "    with open(train_file_path, 'w') as train_file:\n",
    "        train_file.writelines(training_set)\n",
    "\n",
    "    # Remove included data points from the input file\n",
    "    lines = [line for line in lines if line not in training_set]\n",
    "    with open(input_file_path, 'w') as input_file:\n",
    "        input_file.writelines(lines)\n",
    "\n",
    "# Define file paths\n",
    "# Define file paths\n",
    "input_file_path = '/content/drive/MyDrive/(copy)TEMPORAL_num_lit_triple2id.txt'\n",
    "train_file_path = '/content/drive/MyDrive/train_data.txt'\n",
    "\n",
    "# Create the training set and remove data points from the input file\n",
    "create_training_set_and_remove(input_file_path, train_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eD2xD9rOpoF1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VtT0s2R4ITvK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2t5DUnaTITz8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RGIWxwzIpoIz"
   },
   "outputs": [],
   "source": [
    "def check_and_output_lines(input_file_path, output_file_path):\n",
    "    # Read the content of the input file\n",
    "    with open(input_file_path, 'r') as input_file:\n",
    "        lines = input_file.readlines()\n",
    "\n",
    "    # Check each line and output lines where the 3rd element has length != 4\n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        for line in lines:\n",
    "            elements = line.strip().split('\\t')\n",
    "            if len(elements[0]) > 5:\n",
    "                output_file.write(line)\n",
    "\n",
    "# Define file paths\n",
    "input_file_path = '/content/drive/MyDrive/num_lit_triple2id.txt'\n",
    "output_file_path = '/content/drive/MyDrive/output_lines.txt'\n",
    "\n",
    "# Check lines and output those where the 3rd element has length != 4\n",
    "check_and_output_lines(input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46ueJChwF2Ht"
   },
   "outputs": [],
   "source": [
    "def find_lines_with_condition(input_file_path):\n",
    "    # Read the content of the input file\n",
    "    with open(input_file_path, 'r') as input_file:\n",
    "        lines = input_file.readlines()\n",
    "\n",
    "    # Identify line numbers where the 3rd element has length != 4\n",
    "    lines_with_condition = []\n",
    "    for i, line in enumerate(lines):\n",
    "        elements = line.strip().split('\\t')\n",
    "        if len(elements[0]) > 5:\n",
    "            lines_with_condition.append(i + 1)  # Adding 1 to convert from zero-based index to line number\n",
    "\n",
    "    return lines_with_condition\n",
    "\n",
    "# Define file path\n",
    "input_file_path = '/content/drive/MyDrive/train_data.txt'\n",
    "\n",
    "# Find line numbers where the 3rd element has length != 4\n",
    "lines_with_condition = find_lines_with_condition(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-PKXlYkLGxsr",
    "outputId": "0d1f4027-9c7f-472d-8ed6-af41c152399d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12342, 14346, 16903]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_with_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7nctvFsEIS2W",
    "outputId": "6389d64a-e741-4779-8940-f671992ddc2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys with values longer than 5 characters: []\n"
     ]
    }
   ],
   "source": [
    "def keys_with_long_values(dictionary):\n",
    "    return [key for key, value in dictionary.items() if len(value) > 5]\n",
    "\n",
    "# Example dictionary\n",
    "my_dict = {'key1': 'value123', 'key2': 'short', 'key3': 'longvalue', 'key4': 'anotherlongvalue'}\n",
    "\n",
    "# Get keys with values longer than 5 characters\n",
    "result_keys = keys_with_long_values(entity_mapping)\n",
    "\n",
    "# Print or use the result as needed\n",
    "print(f\"Keys with values longer than 5 characters: {result_keys}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "-n2qDHzQJtCT",
    "outputId": "4610ed5b-f33e-4163-ded5-af1965749dfa"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'14166'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_mapping[\"Duchy_of_Savoy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Elg1mjClOPP8",
    "outputId": "c82121b3-9d61-4319-b84f-9ff566ad1f29"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'18583'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_mapping[\"1416\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "XUDMHL-EORuR",
    "outputId": "aaf37e3b-6128-48ad-e914-b8660fad3a87"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'12275'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_mapping[\"Bad_Kreuznach\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "jB3Ph49vPsGp",
    "outputId": "bd1fcba0-b04c-4e55-affe-660ce3c6a68a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'18809'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_mapping[\"1227\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "551yrX1fPsLs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T8COcSKFPsUt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Lc7G7fVPsY-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
