{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHiKC1jRVIj1",
        "outputId": "5ccc914b-45ef-4c99-e51a-f5a8ca797e38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beverly_Adams\twasBornIn\tEdmonton\t1945-11-07\t1945-11-07\n",
            "Al_Gore\twasBornIn\tWashington,_D.C.\t1948-03-31\t1948-03-31\n",
            "Donald_R._McMonagle\twasBornIn\tFlint,_Michigan\t1952-05-14\t1952-05-14\n",
            "Donald_B._Beary\twasBornIn\tHelena,_Montana\t1888-12-04\t1888-12-04\n",
            "Ida_Halpern\twasBornIn\tVienna\t1910-07-17\t1910-07-17\n",
            "João_Paiva\twasBornIn\tLisbon\t1983-02-08\t1983-02-08\n",
            "Vincent_Wong_(Hong_Kong_actor)\twasBornIn\tHong_Kong\t1983-07-07\t1983-07-07\n",
            "Julie_Bishop_(actress)\twasBornIn\tDenver\t1914-08-30\t1914-08-30\n",
            "Bradley_Cooper\twasBornIn\tPhiladelphia\t1975-01-05\t1975-01-05\n",
            "José_Gonçalves_(footballer)\twasBornIn\tLisbon\t1985-09-17\t1985-09-17\n",
            "Harry_Weese\twasBornIn\tEvanston,_Illinois\t1915-06-30\t1915-06-30\n",
            "Roger_MacBride\twasBornIn\tNew_Rochelle,_New_York\t1929-08-06\t1929-08-06\n",
            "James_Neill\twasBornIn\tSavannah,_Georgia\t1860-09-29\t1860-09-29\n",
            "Wendy_Moniz\twasBornIn\tKansas_City,_Missouri\t1969-01-19\t1969-01-19\n",
            "Rob_Wagner\twasBornIn\tDetroit\t1872-08-02\t1872-08-02\n"
          ]
        }
      ],
      "source": [
        "# Specify the file path\n",
        "file_path = '/content/drive/MyDrive/hyte_text_data.txt'\n",
        "\n",
        "# Specify the number of lines to read\n",
        "num_lines_to_read = 15\n",
        "\n",
        "# Open the file in read mode ('r')\n",
        "with open(file_path, 'r') as file:\n",
        "    # Read the specified number of lines\n",
        "    for _ in range(num_lines_to_read):\n",
        "        line = file.readline()\n",
        "\n",
        "        # Check if the line is not empty (end of file)\n",
        "        if not line:\n",
        "            break\n",
        "\n",
        "        # Process or print the line\n",
        "        print(line.strip())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the file path\n",
        "file_path = '/content/drive/MyDrive/TEMPORAL_filtered_literal_data.txt'\n",
        "\n",
        "# Specify the number of lines to read\n",
        "num_lines_to_read = 15\n",
        "\n",
        "# Open the file in read mode ('r')\n",
        "with open(file_path, 'r') as file:\n",
        "    # Read the specified number of lines\n",
        "    for _ in range(num_lines_to_read):\n",
        "        line = file.readline()\n",
        "\n",
        "        # Check if the line is not empty (end of file)\n",
        "        if not line:\n",
        "            break\n",
        "\n",
        "        # Process or print the line\n",
        "        print(line.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpV2qNrjWDUR",
        "outputId": "a33bfdbb-4c71-43e9-b424-c004eb7ec96c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jens_Petersen\twasBornOnDate\t1941\t1941\t1941\n",
            "Avery_Brundage\tdiedOnDate\t1975\t1975\t1975\n",
            "Werner_Herzog\twasBornOnDate\t1942\t1942\t1942\n",
            "Ngaio_Marsh\twasCreatedOnDate\t2010\t2010\t2010\n",
            "Layne_Staley\twasDestroyedOnDate\t1987\t1987\t1987\n",
            "Anne_of_Austria,_Queen_of_Poland\tdiedOnDate\t1598\t1598\t1598\n",
            "Alessandro_Manzoni\tdiedOnDate\t1873\t1873\t1873\n",
            "Cornelius_Castoriadis\twasCreatedOnDate\t2000\t2000\t2000\n",
            "Bradley_Bell\twasBornOnDate\t1964\t1964\t1964\n",
            "Joseph_Jackson_(screenwriter)\twasBornOnDate\t1894\t1894\t1894\n",
            "Sidney_Luft\tdiedOnDate\t2005\t2005\t2005\n",
            "Dewi_Zephaniah_Phillips\tdiedOnDate\t2006\t2006\t2006\n",
            "Erskine_Hamilton_Childers\tdiedOnDate\t1974\t1974\t1974\n",
            "Luigi_Ferrero\twasBornOnDate\t1904\t1904\t1904\n",
            "John_Fante\tdiedOnDate\t1983\t1983\t1983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the file path\n",
        "file_path = '/content/drive/MyDrive/combined_data.txt'\n",
        "\n",
        "# Specify the number of lines to read\n",
        "num_lines_to_read = 15\n",
        "\n",
        "# Open the file in read mode ('r')\n",
        "with open(file_path, 'r') as file:\n",
        "    # Read the specified number of lines\n",
        "    for _ in range(num_lines_to_read):\n",
        "        line = file.readline()\n",
        "\n",
        "        # Check if the line is not empty (end of file)\n",
        "        if not line:\n",
        "            break\n",
        "\n",
        "        # Process or print the line\n",
        "        print(line.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InMdGkVOWDX2",
        "outputId": "67fe0136-31ff-4bef-b09e-0986dcfbd4a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beverly_Adams\twasBornIn\tEdmonton\t1945-11-07\t1945-11-07\n",
            "Al_Gore\twasBornIn\tWashington,_D.C.\t1948-03-31\t1948-03-31\n",
            "Donald_R._McMonagle\twasBornIn\tFlint,_Michigan\t1952-05-14\t1952-05-14\n",
            "Donald_B._Beary\twasBornIn\tHelena,_Montana\t1888-12-04\t1888-12-04\n",
            "Ida_Halpern\twasBornIn\tVienna\t1910-07-17\t1910-07-17\n",
            "João_Paiva\twasBornIn\tLisbon\t1983-02-08\t1983-02-08\n",
            "Vincent_Wong_(Hong_Kong_actor)\twasBornIn\tHong_Kong\t1983-07-07\t1983-07-07\n",
            "Julie_Bishop_(actress)\twasBornIn\tDenver\t1914-08-30\t1914-08-30\n",
            "Bradley_Cooper\twasBornIn\tPhiladelphia\t1975-01-05\t1975-01-05\n",
            "José_Gonçalves_(footballer)\twasBornIn\tLisbon\t1985-09-17\t1985-09-17\n",
            "Harry_Weese\twasBornIn\tEvanston,_Illinois\t1915-06-30\t1915-06-30\n",
            "Roger_MacBride\twasBornIn\tNew_Rochelle,_New_York\t1929-08-06\t1929-08-06\n",
            "James_Neill\twasBornIn\tSavannah,_Georgia\t1860-09-29\t1860-09-29\n",
            "Wendy_Moniz\twasBornIn\tKansas_City,_Missouri\t1969-01-19\t1969-01-19\n",
            "Rob_Wagner\twasBornIn\tDetroit\t1872-08-02\t1872-08-02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input file path\n",
        "input_file_path = '/content/drive/MyDrive/hyte_text_data.txt'\n",
        "\n",
        "# Output file path\n",
        "output_file_path = '/content/drive/MyDrive/sle_entity2id.txt'\n",
        "\n",
        "# Dictionary to store unique values and corresponding integers\n",
        "unique_values_dict = {}\n",
        "\n",
        "# Read the input file and extract unique values\n",
        "with open(input_file_path, 'r') as input_file:\n",
        "    for line in input_file:\n",
        "        # Split the line into elements\n",
        "        elements = line.strip().split()\n",
        "\n",
        "        # Check if there's at least one element\n",
        "        if elements:\n",
        "            # Extract the first element\n",
        "            first_element = elements[0]\n",
        "\n",
        "            # If the value is not in the dictionary, add it with a unique integer\n",
        "            if first_element not in unique_values_dict:\n",
        "                unique_values_dict[first_element] = len(unique_values_dict)\n",
        "\n",
        "# Read the input file and extract unique values\n",
        "with open(input_file_path, 'r') as input_file:\n",
        "    for line in input_file:\n",
        "        # Split the line into elements\n",
        "        elements = line.strip().split()\n",
        "\n",
        "        # Check if there's at least one element\n",
        "        if elements:\n",
        "            # Extract the first element\n",
        "            third_element = elements[2]\n",
        "\n",
        "            # If the value is not in the dictionary, add it with a unique integer\n",
        "            if third_element not in unique_values_dict:\n",
        "                unique_values_dict[third_element] = len(unique_values_dict)\n",
        "\n",
        "# Write unique values with <> symbols and unique integers to the output file\n",
        "with open(output_file_path, 'w') as output_file:\n",
        "    for value, unique_integer in unique_values_dict.items():\n",
        "        output_file.write(f'<{value}>  \\t{unique_integer}\\n')"
      ],
      "metadata": {
        "id": "IHE5k2E4WDnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_file_path = '/content/drive/MyDrive/TEMPORAL_filtered_literal_data.txt'\n",
        "output_file_path = '/content/drive/MyDrive/sle_entity2id.txt'\n",
        "\n",
        "with open(input_file_path, 'r') as input_file:\n",
        "    for line in input_file:\n",
        "        # Split the line into elements\n",
        "        elements = line.strip().split()\n",
        "\n",
        "        # Check if there's at least one element\n",
        "        if elements:\n",
        "            # Extract the first element\n",
        "            third_element = elements[0]\n",
        "\n",
        "            # If the value is not in the dictionary, add it with a unique integer\n",
        "            if third_element not in unique_values_dict:\n",
        "                unique_values_dict[third_element] = len(unique_values_dict)\n",
        "\n",
        "# Write unique values with <> symbols and unique integers to the output file\n",
        "with open(output_file_path, 'w') as output_file:\n",
        "    for value, unique_integer in unique_values_dict.items():\n",
        "        output_file.write(f'<{value}>  \\t{unique_integer}\\n')"
      ],
      "metadata": {
        "id": "R7C-yEZbVafy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the contents of the file\n",
        "with open('/content/drive/MyDrive/TEMPORAL_filtered_literal_data.txt', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Extract unique values from the third column\n",
        "unique_values = set(line.split()[2] for line in lines)\n",
        "\n",
        "# Write the unique values to a new file\n",
        "with open('/content/drive/MyDrive/output_mapping2.txt', 'w') as output_file:\n",
        "    for value in unique_values:\n",
        "        output_file.write(f'<{value}>\\t27530\\n')\n"
      ],
      "metadata": {
        "id": "dfHAEqrOVaoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_files(file1_path, file2_path, output_file_path):\n",
        "    with open(file1_path, 'r') as file1, open(file2_path, 'r') as file2:\n",
        "        content1 = file1.read()\n",
        "        content2 = file2.read()\n",
        "\n",
        "    combined_content = content1 + content2\n",
        "\n",
        "    with open(output_file_path, 'w') as output_file:\n",
        "        output_file.write(combined_content)\n",
        "\n",
        "# Example usage\n",
        "file1_path = '/content/drive/MyDrive/sle_entity2id.txt'  # Replace with your actual file1 path\n",
        "file2_path = '/content/drive/MyDrive/output_mapping2.txt'  # Replace with your actual file2 path\n",
        "output_file_path = '/content/drive/MyDrive/sle_entity2id.txt'  # Replace with your desired output file path\n",
        "\n",
        "combine_files(file1_path, file2_path, output_file_path)"
      ],
      "metadata": {
        "id": "GIphKW8XVaq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_symbols(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r') as input_file:\n",
        "        lines = input_file.readlines()\n",
        "\n",
        "    # Remove < and > symbols from the first column\n",
        "    modified_lines = [line.split('\\t')[0].replace('<', '').replace('>', '').strip() + '\\t' + '\\t'.join(line.split('\\t')[1:]) for line in lines]\n",
        "\n",
        "    with open(output_file_path, 'w') as output_file:\n",
        "        output_file.writelines(modified_lines)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Example usage\n",
        "input_file_path = '/content/drive/MyDrive/sle_entity2id.txt'\n",
        "output_file_path = '/content/drive/MyDrive/USE_sle_entity2id.txt'\n",
        "\n",
        "remove_symbols(input_file_path, output_file_path)"
      ],
      "metadata": {
        "id": "FNE2mLCNatn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input file path\n",
        "input_file_path = '/content/drive/MyDrive/combined_data.txt'\n",
        "\n",
        "# Output file path\n",
        "output_file_path = '/content/drive/MyDrive/sle_relation2id.txt'\n",
        "\n",
        "# Dictionary to store unique values and corresponding integers\n",
        "unique_values_dict = {}\n",
        "\n",
        "# Read the input file and extract unique values\n",
        "with open(input_file_path, 'r') as input_file:\n",
        "    for line in input_file:\n",
        "        # Split the line into elements\n",
        "        elements = line.strip().split()\n",
        "\n",
        "        # Check if there's at least one element\n",
        "        if elements:\n",
        "            # Extract the first element\n",
        "            second_element = elements[1]\n",
        "\n",
        "            # If the value is not in the dictionary, add it with a unique integer\n",
        "            if second_element not in unique_values_dict:\n",
        "                unique_values_dict[second_element] = len(unique_values_dict)\n",
        "\n",
        "# Write unique values with <> symbols and unique integers to the output file\n",
        "with open(output_file_path, 'w') as output_file:\n",
        "    for value, unique_integer in unique_values_dict.items():\n",
        "        output_file.write(f'<{value}>  \\t{unique_integer}\\n')"
      ],
      "metadata": {
        "id": "qLnjt-fjatlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input file path\n",
        "input_file_path = '/content/drive/MyDrive/combined_data.txt'\n",
        "\n",
        "# Output file path\n",
        "output_file_path = '/content/drive/MyDrive/USE_sle_relation2id.txt'\n",
        "\n",
        "# Dictionary to store unique values and corresponding integers\n",
        "unique_values_dict = {}\n",
        "\n",
        "# Read the input file and extract unique values\n",
        "with open(input_file_path, 'r') as input_file:\n",
        "    for line in input_file:\n",
        "        # Split the line into elements\n",
        "        elements = line.strip().split()\n",
        "\n",
        "        # Check if there's at least one element\n",
        "        if elements:\n",
        "            # Extract the first element\n",
        "            second_element = elements[1]\n",
        "\n",
        "            # If the value is not in the dictionary, add it with a unique integer\n",
        "            if second_element not in unique_values_dict:\n",
        "                unique_values_dict[second_element] = len(unique_values_dict)\n",
        "\n",
        "# Write unique values with <> symbols and unique integers to the output file\n",
        "with open(output_file_path, 'w') as output_file:\n",
        "    for value, unique_integer in unique_values_dict.items():\n",
        "        output_file.write(f'{value}  \\t{unique_integer}\\n')"
      ],
      "metadata": {
        "id": "EnrnOqgFatiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entity2id_path = '/content/drive/MyDrive/USE_sle_entity2id.txt'\n",
        "relation2id_path = '/content/drive/MyDrive/USE_sle_relation2id.txt'\n",
        "\n",
        "# Read entity2id and relation2id mappings\n",
        "entity_mapping = {}\n",
        "relation_mapping = {}\n",
        "\n",
        "with open(entity2id_path, 'r') as entity_file:\n",
        "    for line in entity_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        if len(parts) == 2:\n",
        "            entity_mapping[parts[0].strip()] = parts[1]\n",
        "\n",
        "with open(relation2id_path, 'r') as relation_file:\n",
        "    for line in relation_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        if len(parts) == 2:\n",
        "            relation_mapping[parts[0].strip()] = parts[1]"
      ],
      "metadata": {
        "id": "OG5gAjY8atek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_values_to_names(input_file_path, output_file_path, entity_mapping, relation_mapping):\n",
        "    with open(input_file_path, 'r') as input_file:\n",
        "        lines = input_file.readlines()\n",
        "\n",
        "    with open(output_file_path, 'w') as output_file:\n",
        "        for line in lines:\n",
        "            elements = line.strip().split('\\t')\n",
        "            if len(elements) >= 3:\n",
        "                # Replace entity values in the 1st and 3rd columns\n",
        "                entity1 = entity_mapping.get(elements[0], elements[0])\n",
        "                entity2 = entity_mapping.get(elements[2], elements[2])\n",
        "\n",
        "                # Replace relation value in the 2nd column\n",
        "                relation = relation_mapping.get(elements[1], elements[1])\n",
        "\n",
        "                # Keep the 4th and 5th columns unchanged\n",
        "                output_line = f\"{entity1}\\t{relation}\\t{entity2}\\t{elements[3]}\\t{elements[4]}\\n\"\n",
        "\n",
        "                output_file.write(output_line)\n",
        "\n",
        "# Example usage\n",
        "input_file_path = '/content/drive/MyDrive/combined_data.txt'  # Replace with your actual input file path\n",
        "output_file_path = '/content/drive/MyDrive/sle_triple2id.txt'  # Replace with your desired output file path\n",
        "\n",
        "\n",
        "map_values_to_names(input_file_path, output_file_path, entity_mapping, relation_mapping)"
      ],
      "metadata": {
        "id": "BdEBhUg0atbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_values_to_names(input_file_path, output_file_path, entity_mapping, relation_mapping):\n",
        "    with open(input_file_path, 'r') as input_file:\n",
        "        lines = input_file.readlines()\n",
        "\n",
        "    with open(output_file_path, 'w') as output_file:\n",
        "        for line in lines:\n",
        "            elements = line.strip().split('\\t')\n",
        "            if len(elements) >= 3:\n",
        "                # Replace entity values in the 1st and 3rd columns\n",
        "                entity1 = entity_mapping.get(elements[0], elements[0])\n",
        "                entity2 = entity_mapping.get(elements[2], elements[2])\n",
        "\n",
        "                # Replace relation value in the 2nd column\n",
        "                relation = relation_mapping.get(elements[1], elements[1])\n",
        "\n",
        "                # Keep the 4th and 5th columns unchanged\n",
        "                output_line = f\"{entity1}\\t{relation}\\t{entity2}\\t{elements[3]}\\t{elements[4]}\\n\"\n",
        "\n",
        "                output_file.write(output_line)\n",
        "\n",
        "# Example usage\n",
        "input_file_path = '/content/drive/MyDrive/combined_data.txt'  # Replace with your actual input file path\n",
        "output_file_path = '/content/drive/MyDrive/COPY_sle_triple2id.txt'  # Replace with your desired output file path\n",
        "\n",
        "\n",
        "map_values_to_names(input_file_path, output_file_path, entity_mapping, relation_mapping)"
      ],
      "metadata": {
        "id": "HkKLQdCPatXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def shuffle_lines(input_file_path, output_file_path):\n",
        "    with open(input_file_path, 'r') as input_file:\n",
        "        lines = input_file.readlines()\n",
        "        random.shuffle(lines)\n",
        "\n",
        "    with open(output_file_path, 'w') as output_file:\n",
        "        output_file.writelines(lines)\n",
        "\n",
        "# Example usage\n",
        "input_file_path = '/content/drive/MyDrive/COPY_sle_triple2id.txt'  # Replace with your actual input file path\n",
        "output_file_path = '/content/drive/MyDrive/COPY_sle_triple2id.txt' # Replace with your desired output file path\n",
        "\n",
        "shuffle_lines(input_file_path, output_file_path)"
      ],
      "metadata": {
        "id": "H396_l18atOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_training_set_and_remove(input_file_path, train_file_path):\n",
        "    # Read the content of the input file\n",
        "    with open(input_file_path, 'r') as input_file:\n",
        "        lines = input_file.readlines()\n",
        "\n",
        "    # Extract unique values from the first column and the third column:\n",
        "    unique_values = set()\n",
        "    for line in lines:\n",
        "        elements = line.strip().split('\\t')\n",
        "        if len(elements) >= 4:\n",
        "            unique_values.add(elements[0])\n",
        "            unique_values.add(elements[2])\n",
        "\n",
        "    # Initialize the training set and set to track included values\n",
        "    training_set = []\n",
        "    included_values = set()\n",
        "\n",
        "    # Iterate through lines to create the training set\n",
        "    for line in lines:\n",
        "        value1 = line.split()[0]\n",
        "        value2 = line.split()[2]\n",
        "\n",
        "        # Include the line in the training set if it has a unique value\n",
        "        if value1 in unique_values and value1 not in included_values:\n",
        "            training_set.append(line)\n",
        "            included_values.add(value1)\n",
        "            included_values.add(value2)\n",
        "\n",
        "        if value2 in unique_values and value2 not in included_values:\n",
        "            training_set.append(line)\n",
        "            included_values.add(value1)\n",
        "            included_values.add(value2)\n",
        "\n",
        "\n",
        "    # Write the training set to the training file\n",
        "    with open(train_file_path, 'w') as train_file:\n",
        "        train_file.writelines(training_set)\n",
        "\n",
        "    # Remove included data points from the input file\n",
        "    lines = [line for line in lines if line not in training_set]\n",
        "    with open(input_file_path, 'w') as input_file:\n",
        "        input_file.writelines(lines)\n",
        "\n",
        "# Define file paths\n",
        "# Define file paths\n",
        "input_file_path = '/content/drive/MyDrive/COPY_sle_triple2id.txt'\n",
        "train_file_path = '/content/drive/MyDrive/train_data.txt'\n",
        "\n",
        "# Create the training set and remove data points from the input file\n",
        "create_training_set_and_remove(input_file_path, train_file_path)"
      ],
      "metadata": {
        "id": "rF6WKyHsetPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_lines_with_condition(input_file_path):\n",
        "    # Read the content of the input file\n",
        "    with open(input_file_path, 'r') as input_file:\n",
        "        lines = input_file.readlines()\n",
        "\n",
        "    # Identify line numbers where the 3rd element has length != 4\n",
        "    lines_with_condition = []\n",
        "    for i, line in enumerate(lines):\n",
        "        elements = line.strip().split('\\t')\n",
        "        if len(elements[2]) > 5:\n",
        "            lines_with_condition.append(i + 1)  # Adding 1 to convert from zero-based index to line number\n",
        "\n",
        "    return lines_with_condition\n",
        "\n",
        "# Define file path\n",
        "input_file_path = '/content/drive/MyDrive/sle_triple2id.txt'\n",
        "\n",
        "# Find line numbers where the 3rd element has length != 5\n",
        "lines_with_condition = find_lines_with_condition(input_file_path)"
      ],
      "metadata": {
        "id": "C2Eltz8PetSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines_with_condition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzHeuJE_etV-",
        "outputId": "33eabab0-5d11-425c-9a07-660b4816a64b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_unique_values(input_file_path, column_index):\n",
        "    unique_values = set()\n",
        "\n",
        "    with open(input_file_path, 'r') as input_file:\n",
        "        for line in input_file:\n",
        "            elements = line.strip().split('\\t')\n",
        "            if len(elements) > column_index:\n",
        "                unique_values.add(elements[column_index])\n",
        "\n",
        "    return len(unique_values)\n",
        "\n",
        "# Example usage\n",
        "input_file_path = '/content/drive/MyDrive/sle_triple2id.txt'  # Replace with your actual input file path\n",
        "\n",
        "# Count unique values in the first column (column_index=0)\n",
        "unique_values_first_column = count_unique_values(input_file_path, 0)\n",
        "print(f\"Number of unique values in the first column: {unique_values_first_column}\")\n",
        "\n",
        "# Count unique values in the third column (column_index=2)\n",
        "unique_values_third_column = count_unique_values(input_file_path, 2)\n",
        "print(f\"Number of unique values in the third column: {unique_values_third_column}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpcXP9pXetY_",
        "outputId": "460dc8a2-9f1b-41bf-80bc-c77add34d45f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique values in the first column: 23488\n",
            "Number of unique values in the third column: 6352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "apiP4FI9etc0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}